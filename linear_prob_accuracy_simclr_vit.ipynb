{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "918b0144-0799-41e1-b0f4-8096015b6b8a",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8530bb38-9f70-4db1-8035-139f5e2cb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import random \n",
    "from util import Random\n",
    "from configs import SupportedDatasets\n",
    "from sas.approx_latent_classes import clip_approx\n",
    "from sas.subset_dataset import SASSubsetDataset\n",
    "import torch\n",
    "from torch import nn \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from transformers import ViTMAEForPreTraining\n",
    "from evaluate.lbfgs import encode_train_set, train_clf, test_clf\n",
    "from trainer import Trainer\n",
    "from PIL import Image\n",
    "from data_proc.augmentation import ColourDistortion\n",
    "from collections import namedtuple\n",
    "from data_proc.dataset import *\n",
    "from resnet import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe271676-1fbd-4b06-92fd-ebb7be7e30a4",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bd1087c-93a8-4ad7-bd43-5cac25664abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets = namedtuple('Datasets', 'trainset testset clftrainset num_classes stem')\n",
    "\n",
    "def get_datasets(dataset: str, augment_clf_train=False, add_indices_to_data=False, num_positive=2):\n",
    "    CACHED_MEAN_STD = {\n",
    "        'cifar100': ((0.5071, 0.4865, 0.4409), (0.2009, 0.1984, 0.2023)),\n",
    "    }\n",
    "\n",
    "    PATHS = {\n",
    "        'cifar100': '/data/cifar100/',\n",
    "    }\n",
    "\n",
    "    root = PATHS[dataset]\n",
    "\n",
    "    # Data\n",
    "    img_size = 224\n",
    "\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(img_size, interpolation=Image.BICUBIC),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        ColourDistortion(s=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(*CACHED_MEAN_STD[dataset]),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(*CACHED_MEAN_STD[dataset]),\n",
    "    ])\n",
    "\n",
    "    transform_clftrain = transform_test\n",
    "    trainset = testset = clftrainset = num_classes = stem = None\n",
    "    \n",
    "    if dataset == 'cifar100':\n",
    "        dset = torchvision.datasets.CIFAR100\n",
    "        trainset = CIFAR100Augment(root=root, train=True, download=True, transform=transform_train, n_augmentations=num_positive)\n",
    "    clftrainset = dset(root=root, train=True, download=True, transform=transform_clftrain)\n",
    "    testset = dset(root=root, train=False, download=True, transform=transform_test)\n",
    "    num_classes = 100\n",
    "    stem = StemCIFAR\n",
    "\n",
    "    return Datasets(trainset=trainset, testset=testset, clftrainset=clftrainset, num_classes=num_classes, stem=stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1d1c96d-dae2-400f-b0a4-796cfd03da8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "datasets = get_datasets('cifar100')\n",
    "clftrainloader = torch.utils.data.DataLoader(\n",
    "    dataset=datasets.clftrainset,\n",
    "    batch_size=512, \n",
    "    shuffle=False, \n",
    "    num_workers=4, \n",
    "    pin_memory=True\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    dataset=datasets.testset,\n",
    "    batch_size=512, \n",
    "    shuffle=False, \n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9c25b8-d38d-472f-8911-7b439f234f42",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43933087-666d-478f-8adf-e24bca2e2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViTMAEForPreTraining.from_pretrained('facebook/vit-mae-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4254828c-7a74-46c8-93e1-9892d485b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProxyModel(nn.Module):\n",
    "    def __init__(self, net):\n",
    "        super().__init__()\n",
    "        self.encoder = net.vit\n",
    "        self.representation_dim = 768\n",
    "    def forward(self, inputs):\n",
    "        return self.encoder(inputs).last_hidden_state[:,0,:].squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc135ebf-7b4a-4330-bd6e-5f161eb3d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ProxyModel(model).to('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2a6059-f2bb-4f26-9f2c-bdad6c6ebd92",
   "metadata": {},
   "source": [
    "# Linear probing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f396bc2-8ab5-44bc-9e17-bc9110d509a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    device='cuda:0',\n",
    "    distributed=False,\n",
    "    rank=0,\n",
    "    world_size=1,\n",
    "    net=net,\n",
    "    critic=None,\n",
    "    trainloader=None,\n",
    "    clftrainloader=clftrainloader,\n",
    "    testloader=testloader,\n",
    "    num_classes=datasets.num_classes,\n",
    "    optimizer=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a59e7df2-79a3-40f5-ab53-df6c757e71d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoded 97/98: █████████████████████████████████| 98/98 [00:43<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L2 Regularization weight: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.282 | Train Acc: 73.552% : ███████████| 100/100 [00:19<00:00,  5.02it/s]\n",
      "Loss: 1.235 | Test Acc: 65.970% : ██████████████| 20/20 [00:09<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc = trainer.test()\n",
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
